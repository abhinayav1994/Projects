@@ -0,0 +1,112 @@
install.packages("tidyverse")
library(tidyverse)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
install.packages("readxl")
library(readxl)
data = read_excel("Cellphone.xlsx",sheet = 2)
summary(data)
is.na(data) #dropping null values
data=na.omit(data)

data_fact=data[,-c(1,3,4)]
data_num=data[,-c(12,13,14)]
tr(data_fact)
str(data_num)


str(data)
cor(data) # to find the correlation between different variables
boxplot(data)
hist(data$Churn)
hist(data$AccountWeeks)
hist(data$ContractRenewal)
hist(data$DataPlan)
hist(data$DataUsage)
hist(data$CustServCalls)
hist(data$DayMins) 
hist(data$DayCalls)
hist(data$MonthlyCharge)
hist(data$OverageFee)
hist(data$RoamMins)


##Convert the Dependent variable and 2 other predicors into factors
data$Churn_factor=as.factor(data$Churn)
data$ContractRenewal_factor=as.factor(data$ContractRenewal)
data$DataPlan_factor=as.factor(data$DataPlan)
summary(data)
str(data)

#splitting data with 70:30 propotion
# Using the Random number generator
set.seed(103)
library(caret)

Ndata<-createDataPartition(data_fact$Churn, p=0.7)
Ndatatrain<-subset(Ndata, sample = TRUE)
Ndatatest<-subset(Ndata, sample = FALSE)
LogRegModel<-glm(Churn~AccountWeeks+CustServCalls+DayCalls+RoamMins+ContractRenewal_fact,data=Ndatatrain,family=binomial)
summary(LogRegModel) #This will give the value of slops and intercepts

#Testing Logistic regression analysis

#Log likelihood test

install.packages("lmtest")
install.packages("zoo")

library(lmtest)
lrtest(LogRegModel)

#Based on the chi square value, the churn depends on
#Contract Renewal, Day Calls,Account Weeks,Data Plan, Data Usage,Customer Service Calls, Day Mins,Monthly Charge, Overage Fee & Roam Mins

#Pseudo R square Test
install.packages("pscl")
library(pscl)
pR2(LogRegModel)
# the Mcfaddedn number shows the value 100% which tells us that the model is a perfect fit
# Training the data

library(caret)
predictionx<-predict(LogRegModel, type="response",data= Ndatatrain)
predictionx<-ifelse(predictionx>0.5,0,1)
table(Actual=Ndatatrain$ContractRenewal_factor,predictionx)

#Predicting the outcomes of this model
predictedresponse<-predict(LogRegModel,type = "response",data=Ndatatest)
predictedresponse<-ifelse(predictedresponse>0.5,0,1)
table(Actual=predictedresponse,Ndatatest)


#Use KNN Classifier 
#normalize the test & train data
normal=function(x){return(x-min(x))/(max(x)-min(x))}
normal.data=as.data.frame(lapply(data_fact[,-c(6,7,8)],normal))
normal.data_fact=cbind(data_fact[,c(6,7,8)],normal.data)
#Splitting the data into train and test data based on normalized data
install.packages("caTools")
library(caTools)
sample = sample.split(normal.data_fact$Churn_factor, SplitRatio = 0.70)
normal_train = subset(normal.data_fact, sample = TRUE)
normal_test  = subset(normal.data_fact, sample = FALSE)
library(class)
library(caret)

knn.pred = knn(normal_train[-c(1)], normal_test[,-c(1)], normal_train[,1], k = 19) 
table.knn = table(normal_test$Churn, knn.pred)
table.knn
sum(diag(table.knn)/sum(table.knn)) 
confusionMatrix(table.knn)

#Naives Bayes theorem works well when we have multiple classes 
install.packages("e1071")
library(e1071)
NBtest = naiveBayes(Churn_fact~AccountWeeks+CustServCalls+DayCalls+RoamMins+ContractRenewal_fact, data = Ndatatrain)
predNBtest = predict(NBtest, Ndatatest, type = "class")
tab.NB = table(test[,8], predNBtest)
sum(diag(tab.NB)/sum(tab.NB))
confusionMatrix(tab.NB)
